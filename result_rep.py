#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Mar 17 16:10:31 2024

@author: junqi
"""

import matplotlib.pyplot as plt
import numpy as np

def create_acc_loss_graph(train_acc, train_loss, test_acc, test_loss):
    fig, axes = plt.subplots(ncols=2, nrows=1, dpi=300)
    fig.set_size_inches(9, 3)
    ax1, ax2 = axes[0], axes[1]
    
    ax1.plot(train_acc, '-o', label="train", markersize=4)
    ax1.plot(test_acc, '--+', label="test", markersize=4)
    ax1.set_xlabel('Epoch')
    ax1.set_ylabel('Accuracy')
    ax1.legend(loc=3)
    
    ax2.plot(train_loss, '-o', label='train', markersize=4)
    ax2.plot(test_loss, '--+', label='test', markersize=4)
    ax2.set_xlabel('Epoch')
    ax2.set_ylabel('Loss')
    ax2.legend(loc=1)
    
    # Plot the parameters
    ax1.set_ylim(0, np.max([np.max(train_acc), np.max(test_acc)]) + 0.1)
    ax2.set_ylim(-0.1, np.max([np.max(train_loss), np.max(test_loss)]) + 0.1)
    ax1.grid(True, which='both', linewidth=0.1)
    ax2.grid(True, which='both', linewidth=0.1)
    plt.tight_layout()
    plt.show()
    

test_loss_resnet50_vqc_rep = [0.4950886845588684, 0.41630049765110017, 0.35897996842861174,
                              0.3336516922712326, 0.3435567596554756,  0.30330298602581024,
                              0.2832687324285507, 0.2597878542542458,  0.273547106385231,
                              0.2664652940630913, 0.2665350720286369,  0.2759634259343147,
                              0.2784881517291069, 0.24541054129600526, 0.2505351811647415,
                              0.24776876389980315,0.25017851650714873, 0.2935437232255936,
                              0.24267778545618057,0.2473266738653183,  0.24481061488389969,
                              0.26148321241140365,0.2639072811603546,  0.2656039801239967,
                              0.25628331750631334,0.25656253308057786, 0.24275481283664704,
                              0.2281750038266182, 0.2279885283112526,  0.24220371574163438]

test_acc_resnet50_vqc_rep = [0.905, 0.9425, 0.9675, 0.9675, 0.935, 0.97, 0.97, 0.985,
                             0.9675, 0.9825, 0.9725, 0.965, 0.965, 0.9875, 0.9775,
                             0.9725, 0.9675, 0.94, 0.975, 0.97, 0.9675, 0.9575, 0.9525,
                             0.955, 0.955, 0.9575, 0.9675, 0.97, 0.975, 0.975]

test_loss_resnet18_vqc_rep = [0.3783230513334274, 0.2970618063211441, 0.24970171242952346,
                              0.21748773008584976, 0.2014513996243477, 0.1953120681643486,
                              0.19410947382450103, 0.19322701781988144, 0.19175137758255004,
                              0.19084487318992616, 0.19023329317569732, 0.18971285074949265,
                              0.18975668430328368, 0.18944677889347075, 0.18969737023115157,
                              0.1890857747197151, 0.18901798874139786, 0.18903965651988983,
                              0.18915311336517335, 0.18925720244646071, 0.18921372771263123,
                              0.18914684176445007, 0.18884778648614883, 0.18879752725362778,
                              0.188751979470253, 0.18870083570480348, 0.188690382540226,
                              0.18867795020341874, 0.1886621132493019, 0.18865405559539794]

test_acc_resnet18_vqc_rep = [0.9875, 1.0, 1.0, 1.0, 1.0, 1.0, 0.9975, 0.9975, 1.0,
                             1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0,
                             1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]

test_loss_pca_vqc_rep = [0.7185184824466705, 0.7066254758834839, 0.6978536379337311,
                         0.691483449935913, 0.686453869342804, 0.681891324520111,
                         0.6770896232128143, 0.6717682039737701, 0.6662592649459839,
                         0.6611617946624756, 0.6568346166610718, 0.653304089307785,
                         0.6504391968250275, 0.6480901551246643, 0.6461384344100952,
                         0.6445020246505737, 0.6431259727478027, 0.6419716489315033,
                         0.6410088407993316, 0.6402107918262482, 0.6395526242256164,
                         0.6390110862255096, 0.6385650670528412, 0.6381956207752227,
                         0.6378866672515869, 0.6376243162155152, 0.637396891117096,
                         0.6371945512294769, 0.6370088970661163, 0.6368326890468597]

test_acc_pca_vqc_rep = [0.435, 0.47, 0.4925, 0.4925, 0.5175, 0.575, 0.625,
                        0.63, 0.6375, 0.65, 0.6475, 0.6525, 0.65, 0.6525,
                        0.65, 0.6525, 0.6575, 0.66, 0.6575, 0.6525, 0.655,
                        0.6575, 0.66, 0.66, 0.66, 0.66, 0.6575, 0.6575,
                        0.655, 0.6575]


fig, axes = plt.subplots(ncols=2, nrows=1, dpi=300)
fig.set_size_inches(12, 4)
ax1, ax2 = axes[0], axes[1]
    
ax1.plot(test_acc_pca_vqc_rep, '-o', label="PCA+VQC", markersize=4)
ax1.plot(test_acc_resnet18_vqc_rep, '--+', label="Pre-ResNet18+VQC", markersize=4)
ax1.plot(test_acc_resnet50_vqc_rep, '--', label="Pre-ResNet50+VQC", markersize=4)
ax1.set_xlabel('Epoch')
ax1.set_ylabel('Accuracy')
ax1.legend(loc=4)

ax2.plot(test_loss_pca_vqc_rep, '-o', label='PCA+VQC', markersize=4)
ax2.plot(test_loss_resnet18_vqc_rep, '--+', label='Pre-ResNet18+VQC', markersize=4)
ax2.plot(test_loss_resnet50_vqc_rep, '--', label='Pre-ResNet50+VQC', markersize=4)
ax2.set_xlabel('Epoch')
ax2.set_ylabel('Loss')
ax2.legend(loc=2)

fig.savefig('result_rep.jpg', dpi=300)
